## Ticket Cliente (AppBodasdehoy) ‚Üí Proveedor Backend IA
**Asunto:** `/webapi/chat/auto` se queda colgado (timeout) aunque `/health` responde OK

Hola equipo,

Gracias por la ‚ÄúRespuesta Final‚Äù y por las correcciones (UnboundLocalError, fallback por cr√©ditos y filtrado de modelos).
Como cliente, al intentar validar en **producci√≥n** (`api-ia.bodasdehoy.com`) tenemos un **bloqueo actual**: el endpoint de chat est√° haciendo **timeout**.

---

### ‚úÖ Contexto
- **Base URL:** `https://api-ia.bodasdehoy.com`
- **Development:** `bodasdehoy`
- **Uso:** Copilot (iframe) / LobeChat integrado en AppBodasdehoy

---

## ‚ùó Problema (bloqueante)
**`POST /webapi/chat/auto` se queda colgado (no responde)**
- `GET /health` ‚Üí **200 OK**
- `POST /webapi/chat/auto` ‚Üí **timeout** (30s sin recibir bytes)

Esto impide validar que los fixes est√©n funcionando y rompe el flujo del Copilot (la request no retorna ni 200 ni 503 estructurado).

---

## üß™ Pruebas reproducibles (copiar/pegar)

### 1) Health (OK)
```bash
curl -i "https://api-ia.bodasdehoy.com/health"
```

### 2) Chat auto (stream:false) ‚Äî timeout
```bash
curl -i --max-time 30 -X POST "https://api-ia.bodasdehoy.com/webapi/chat/auto" \
  -H "Content-Type: application/json" \
  -H "X-Development: bodasdehoy" \
  -H "X-Request-Id: client_timeout_check_001" \
  --data '{"messages":[{"role":"user","content":"ping"}],"stream":false}'
```

### 3) Chat auto (stream:true) ‚Äî (si aplica)
```bash
curl -i --max-time 30 -X POST "https://api-ia.bodasdehoy.com/webapi/chat/auto" \
  -H "Content-Type: application/json" \
  -H "X-Development: bodasdehoy" \
  -H "X-Request-Id: client_timeout_check_stream_001" \
  --data '{"messages":[{"role":"user","content":"ping"}],"stream":true}'
```

---

## ‚úÖ Comportamiento esperado (contrato)
- **√âxito:** HTTP `200` con `success:true` + `response`/`message` + `provider` + `model` + `trace_id`
- **Error:** HTTP `503` con `success:false` + `error` + `error_code` + `trace_id` + `suggestion`
- **Importante:** responder en pocos segundos (ideal <5s) y **no dejar colgada la request**.

---

## ‚ùì Preguntas concretas
1) **Deploy**
- ¬øConfirm√°is que los fixes descritos est√°n desplegados en `api-ia.bodasdehoy.com`?
- Indicad **commit/tag/fecha**.

2) **Disponibilidad / saturaci√≥n**
- ¬øTen√©is incidentes de carga / deadlocks / colas / upstream colgado en `/webapi/chat/*`?
- Vemos `/health` OK pero `/webapi/chat/auto` timeout.

3) **Pol√≠tica de timeouts**
- ¬øPod√©is garantizar que si el upstream est√° degradado, el backend responda **503 r√°pido** en vez de colgar la request?

4) **MongoDB / Keys (seg√∫n vuestra respuesta previa)**
- Si MongoDB no est√° accesible, la lectura desde `lobeChatConfig.aiProviders.*` (ubicaci√≥n principal de la gu√≠a) no ocurre.
- ¬øCu√°ndo vais a configurar `MONGODB_URI` en producci√≥n para leer la ubicaci√≥n principal?

---

## Nota (lado cliente)
En frontend ya mostramos overlay con reporte y evitamos ‚Äúcargando infinito‚Äù, pero dependemos de que el backend responda (200 o 503 estructurado) y no se quede colgado.

Gracias.

